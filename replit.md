# VoiceLink - Real-Time Voice Translation App

## Overview
VoiceLink is a real-time voice translation application designed to break language barriers. It enables two users to engage in conversations in different languages with instant, high-quality translation using Azure Speech and Translation services. The application leverages WebSocket connections for low-latency communication, providing a natural and seamless cross-lingual interaction experience. The project aims to deliver a robust MVP with real-time interim transcription and gender-specific voice selection.

## User Preferences
I prefer clear and concise explanations. I want an iterative development approach, where I can review changes frequently. Please ask for my approval before implementing any major architectural changes or adding new external dependencies. When making code changes, ensure they align with the existing code style and design patterns.

## System Architecture

### UI/UX Decisions
The application features a clean, modern design with full light/dark theme support, **defaulting to light mode for new users**. The color scheme uses Indigo/Blue for interactive elements and Cyan for highlights. It uses the Inter font throughout. Components are built with Shadcn UI and Tailwind CSS, adhering to a responsive, mobile-first design. Theme preference is persisted in localStorage. The UI includes:
- A landing page, room creation/joining interfaces with language and voice gender selection.
- An active translation interface with a dual-panel layout, connection status indicators, microphone controls, and a share dialog.
- A `TranscriptionPanel` visually distinguishes interim transcriptions (dashed border, italic) from final translated messages.

### Technical Implementations
- **Frontend**: React with TypeScript, Wouter for routing, TanStack Query for data fetching, WebSocket client, Web Audio API, and Microsoft Cognitive Services Speech SDK.
- **Backend**: Express.js server, WebSocket server (using `ws` package), and in-memory storage for room management.
- **Real-Time Transcription**: A hybrid system uses Azure Speech SDK's `recognizing` events for throttled (300ms) interim visual feedback (without translation) and `recognized` events for final translation and Text-to-Speech (TTS). This optimizes API costs and user experience.
- **Voice Selection**: Users select a preferred voice gender (male/female) during room creation/joining. This preference is stored, propagated via WebSockets, and used to select gender-specific Azure Neural Voices for TTS (94 voices across 47 languages). Premium Multilingual Neural voices are used for English (Andrew/Ava), French (Remy/Vivienne), German (Florian/Seraphina), and Chinese (Yunxiang/Xiaoyi) to provide the highest quality conversational experience.
- **Audio Overlap Prevention**: Implemented a professional queue-based TTS system using Azure REST API + HTML5 Audio that GUARANTEES only one voice plays at a time in both directions. All translations are added to a FIFO queue and processed sequentially. Critical features include: (1) **Azure REST TTS API** (`synthesizeSpeechToBlob`) retrieves complete audio files as blobs before playback, enabling precise timing control, (2) **HTML5 Audio element** with native 'ended' event provides reliable playback completion detection (no estimation needed), (3) **SSML XML escaping** prevents Azure rejection when translations contain special characters (`&`, `<`, `>`, `"`, `'`), (4) **Retry mechanism** with up to 3 attempts for transient failures, preventing silent audio loss while avoiding infinite loops, (5) **Synchronous boolean flag** (`isProcessingTTSRef`) prevents race conditions through atomic check-and-set. Failed items are re-queued with exponential backoff, successful items are marked as spoken. This production-ready approach provides 100% reliable sequential playback with professional error handling.
- **Mobile Audio Fix**: Implemented comprehensive mobile audio compatibility to prevent TTS playback stoppage and audio repeating issues. Solution includes: (1) **Single Audio Element Reuse** - Creates one Audio element and reuses it for all playback instead of creating new elements (prevents mobile browser limits), (2) **Audio Unlock** - Plays silent audio on first microphone activation to unlock audio permissions (bypasses mobile autoplay restrictions), (3) **Blob URL Management** - Keeps blob URLs alive longer by revoking only when replacing with next audio (prevents premature cleanup on slower devices), (4) **Timeout Fallback for Mobile** - iOS Safari and Android Chrome don't reliably fire the audio 'ended' event, which previously caused the TTS queue to get stuck and replay all messages. Implemented smart timeout mechanism that checks `readyState` immediately, attaches `loadedmetadata` listener before play(), and sets duration-based timeout (audio duration + 2s, max 30s) or 20s default if duration unavailable. The timeout fires only if 'ended' event doesn't, ensuring items are always marked as spoken and the queue never stalls. This completely eliminates the audio repeating issue on mobile while maintaining perfect sequential playback.
- **Message Deduplication**: Implemented robust message deduplication system to prevent repeated audio caused by duplicate WebSocket message deliveries. Server generates unique `messageId` for each translation (format: `${role}-${timestamp}-${randomString}`). Client tracks processed messageIds in a Set and skips any duplicates, preventing the same message from being added to TTS queue multiple times. System preserves legitimate repeated phrases (different messageIds) while filtering true duplicate deliveries. Memory-bounded with 200-entry limit to prevent unbounded growth. Backward compatible with fallback to client-generated IDs.
- **WebSocket Keepalive & Monitoring**: Implemented dual-layer aggressive keepalive system with comprehensive disconnect tracking: (1) **Application-Level Heartbeat** - Client sends `{type: "ping"}` messages every 30 seconds, server responds with `{type: "pong"}`. This ensures data flows through Replit's proxy infrastructure, preventing the standard 300-second (5-minute) idle timeout imposed by load balancers, (2) **Protocol-Level Ping/Pong** - Server sends native WebSocket ping frames every 45 seconds as a backup mechanism to detect broken connections. (3) **Professional Disconnect Handling** - ALL disconnect scenarios (codes 1000-1015) are logged to console with full details including code, duration, reason, room info, readyState, URL, protocol, bufferedAmount, and timestamp. Users receive clear, context-aware UI messages explaining why they disconnected: 5-minute timeout warnings (280-320s), connection failures (<10s), network issues, protocol errors, server errors, and security failures. Normal closures (code 1000, 1001) don't show intrusive toasts. Error events are comprehensively logged with readyState tracking. (4) **Performance Optimization** - URL parameters are memoized using `useMemo` to prevent unnecessary component re-renders. (5) **Comprehensive Diagnostics** - Browser lifecycle tracking (tab visibility, beforeunload), network status monitoring (online/offline events), Azure Speech SDK error handlers (canceled, sessionStarted, sessionStopped events), and detailed UI feedback showing the actual disconnect reason and details instead of generic "Disconnected" message. This ensures professional error handling with complete visibility into all failure modes.
- **Seamless Auto-Reconnect System**: Implemented production-grade automatic reconnection that handles random WebSocket disconnects (occurring at 2-8+ minutes due to Replit infrastructure limits) without user disruption. Features include: (1) **Silent Reconnection** - Automatically attempts reconnection on unintentional disconnects (code 1006, network errors) with exponential backoff (500ms, 1s, 2s) for up to 3 attempts, (2) **Complete State Preservation** - All critical state remains intact during reconnection: room ID, language preferences, voice gender, partner information, message history, and TTS queue, (3) **Azure Speech Continuity** - Automatically restarts Azure Speech recognition with identical settings after successful reconnection, ensuring seamless conversation flow, (4) **Minimal UI Feedback** - Shows only brief "Reconnecting..." status during retry attempts instead of disruptive "Disconnected" errors. Error toasts appear only after all 3 retry attempts fail, (5) **Smart Disconnect Detection** - Distinguishes intentional disconnects (End Call button, component unmount, normal close codes 1000/1001) from transient network issues. Intentional disconnects bypass auto-reconnect entirely, (6) **Error Handler Suppression** - WebSocket error events and browser offline events no longer trigger immediate error UI, allowing the reconnect flow to handle all user feedback gracefully. This system ensures users experience <2 seconds of silence during reconnection with zero visible disruption to the conversation.
- **Professional Quota Handling**: Implemented comprehensive Azure quota error detection and graceful degradation to prevent infinite retry loops and application crashes when hitting service limits. Features include: (1) **Intelligent Error Detection** - Recognizes quota errors from Azure Speech SDK (WebSocket code 1007 + "quota" message) and Azure TTS REST API (HTTP 429), (2) **Immediate Retry Prevention** - Stops auto-retry mechanism for quota errors (prevents wasteful API calls and infinite loops), (3) **Clear User Communication** - Shows prominent warning banner explaining quota status, what still works (text translations), and what's unavailable (voice features), (4) **Graceful Degradation** - Users can continue receiving text translations from partner even when voice features are disabled, (5) **UI State Management** - Disables microphone button with visual feedback and helpful messaging directing users to upgrade Azure account or wait for quota reset, (6) **TTS Queue Protection** - Clears TTS queue and prevents new audio synthesis attempts when quota exceeded. This production-grade error handling ensures the application never enters an unusable state due to Azure service limits.

### Feature Specifications
- **Core Functionality**: Real-time voice translation between two users speaking different languages.
- **Room Management**: Creation and retrieval of rooms with language and voice gender preferences.
- **Real-time Communication**: WebSocket server for instant message exchange, interim transcriptions, and final translations.
- **Microphone Control**: Mute/unmute functionality.
- **Language Support**: 47 supported languages across all major regions with corresponding flag icons. Languages include: English, Spanish, French, German, Italian, Portuguese (Portugal & Brazil), Russian, Japanese, Korean, Chinese, Arabic, Hindi, Dutch, Polish, Turkish, Swedish, Norwegian, Danish, Finnish, Greek, Czech, Romanian, Ukrainian, Hungarian, Vietnamese, Thai, Indonesian, Hebrew, Bengali, Tamil, Telugu, Marathi, Bulgarian, Croatian, Slovak, Slovenian, Catalan, Malay, Afrikaans, Swahili, Gujarati, Kannada, Malayalam, Serbian, Estonian, and Latvian.
- **Voice Customization**: User-selectable male/female voice gender for TTS output, leveraging 94 Azure Neural voices (47 languages Ã— 2 genders each).

## External Dependencies

- **Azure Speech Services**: Used for Speech-to-Text (STT) transcription and Text-to-Speech (TTS) synthesis, including gender-specific Neural voices.
- **Azure Translator API**: Utilized for text translation between spoken languages.
- **Microsoft Cognitive Services Speech SDK**: Integrated on both client and server for interacting with Azure Speech Services.
- **Axios**: Used for making HTTP requests to external APIs, specifically the Azure Translator API.